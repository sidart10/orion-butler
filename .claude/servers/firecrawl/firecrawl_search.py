from typing import Any, Dict, List, Optional
from pydantic import BaseModel, Field
from typing import Literal

class FirecrawlSearchParams(BaseModel):
    """Parameters for firecrawl_search"""
    query: str
    limit: Optional[float] = None
    tbs: Optional[str] = None
    filter: Optional[str] = None
    location: Optional[str] = None
    sources: Optional[List[Dict[str, Any]]] = None
    scrapeOptions: Optional[Dict[str, Any]] = None

async def firecrawl_search(params: FirecrawlSearchParams) -> Dict[str, Any]:
    """
    
Search the web and optionally extract content from search results. This is the most powerful web search tool available, and if available you should always default to using this tool for any web search needs.

The query also supports search operators, that you can use if needed to refine the search:
| Operator | Functionality | Examples |
---|-|-|
| `""` | Non-fuzzy matches a string of text | `"Firecrawl"`
| `-` | Excludes certain keywords or negates other operators | `-bad`, `-site:firecrawl.dev`
| `site:` | Only returns results from a specified website | `site:firecrawl.dev`
| `inurl:` | Only returns results that include a word in the URL | `inurl:firecrawl`
| `allinurl:` | Only returns results that include multiple words in the URL | `allinurl:git firecrawl`
| `intitle:` | Only returns results that include a word in the title of the page | `intitle:Firecrawl`
| `allintitle:` | Only returns results that include multiple words in the title of the page | `allintitle:firecrawl playground`
| `related:` | Only returns results that are related to a specific domain | `related:firecrawl.dev`
| `imagesize:` | Only returns images with exact dimensions | `imagesize:1920x1080`
| `larger:` | Only returns images larger than specified dimensions | `larger:1920x1080`

**Best for:** Finding specific information across multiple websites, when you don't know which website has the information; when you need the most relevant content for a query.
**Not recommended for:** When you need to search the filesystem. When you already know which website to scrape (use scrape); when you need comprehensive coverage of a single website (use map or crawl.
**Common mistakes:** Using crawl or map for open-ended questions (use search instead).
**Prompt Example:** "Find the latest research papers on AI published in 2023."
**Sources:** web, images, news, default to web unless needed images or news.
**Scrape Options:** Only use scrapeOptions when you think it is absolutely necessary. When you do so default to a lower limit to avoid timeouts, 5 or lower.
**Optimal Workflow:** Search first using firecrawl_search without formats, then after fetching the results, use the scrape tool to get the content of the relevantpage(s) that you want to scrape

**Usage Example without formats (Preferred):**
```json
{
  "name": "firecrawl_search",
  "arguments": {
    "query": "top AI companies",
    "limit": 5,
    "sources": [
      "web"
    ]
  }
}
```
**Usage Example with formats:**
```json
{
  "name": "firecrawl_search",
  "arguments": {
    "query": "latest AI research papers 2023",
    "limit": 5,
    "lang": "en",
    "country": "us",
    "sources": [
      "web",
      "images",
      "news"
    ],
    "scrapeOptions": {
      "formats": ["markdown"],
      "onlyMainContent": true
    }
  }
}
```
**Returns:** Array of search results (with optional scraped content).


    Args:
        params: Tool parameters

    Returns:
        Tool execution result
    """
    from runtime.mcp_client import call_mcp_tool
    from runtime.normalize_fields import normalize_field_names

    # Call tool
    result = await call_mcp_tool("firecrawl__firecrawl_search", params.model_dump(exclude_none=True))

    # Defensive unwrapping
    unwrapped = getattr(result, "value", result)

    # Apply field normalization
    normalized = normalize_field_names(unwrapped, "firecrawl")

    return normalized
